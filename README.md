# 🌤️ Nikhil's Custom Airflow ETL Pipeline – Weather Data

This project demonstrates an end-to-end ETL (Extract, Transform, Load) data pipeline using **Apache Airflow** to fetch weather data from an API, process it, and store it for further analysis.

I customized this project as part of my data engineering portfolio to showcase my understanding of data pipelines, orchestration, and real-time scheduling.

---

## 🔧 What I Customized

- ✅ Changed DAG ID to `nikhil_weather_etl` for personal branding
- ✅ Updated schedule to run every **15 minutes** using cron expression
- ✅ Added logging for success confirmation
- ✅ Updated metadata (`owner`, `email`, `description`)
- ✅ Cleaned and optimized the DAG structure

---

## 🧠 What I Learned

- Orchestrating ETL tasks using Apache Airflow
- Working with DAGs, Operators, and scheduling
- Integrating external APIs into data pipelines
- Customizing Python scripts for modular ETL design
- Structuring Airflow projects using best practices

---

## 🔗 Project Structure


