# ğŸŒ¤ï¸ Nikhil's Custom Airflow ETL Pipeline â€“ Weather Data

This project demonstrates an end-to-end ETL (Extract, Transform, Load) data pipeline using **Apache Airflow** to fetch weather data from an API, process it, and store it for further analysis.

I customized this project as part of my data engineering portfolio to showcase my understanding of data pipelines, orchestration, and real-time scheduling.

---

## ğŸ”§ What I Customized

- âœ… Changed DAG ID to `nikhil_weather_etl` for personal branding
- âœ… Updated schedule to run every **15 minutes** using cron expression
- âœ… Added logging for success confirmation
- âœ… Updated metadata (`owner`, `email`, `description`)
- âœ… Cleaned and optimized the DAG structure

---

## ğŸ§  What I Learned

- Orchestrating ETL tasks using Apache Airflow
- Working with DAGs, Operators, and scheduling
- Integrating external APIs into data pipelines
- Customizing Python scripts for modular ETL design
- Structuring Airflow projects using best practices

---

## ğŸ”— Project Structure


